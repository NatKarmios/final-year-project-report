%!TEX root = ../main.tex
%chktex-file 26
%chktex-file 36

\chapter{Background}\label{sec:background}

\section{Separation Logic --- theory and tooling}\label{sec:background:sl-and-tools}

Proposed in 1969, Tony Hoare's \textit{Hoare Logic} provided a standardised
means of reasoning about programs and their correctness~\cite{hoare}. The key
principle of this logic is the Hoare Triple, denoting that if a certain
pre-condition $P$ holds, and code command $C$ is run (and terminates without
failing), then the post-condition $Q$ is guaranteed to hold. This is presented
in the form of a \textit{Hoare triple}:
\[
  \triple{P}{C}{Q}
\]

Whilst this is a strong foundation for reasoning about programs, anything more
than the simplest of functions become hugely cumbersome to work with,
particularly concerning operations on heap-allocated memory. In 2001, Peter
O'Hearn and John Reynolds proposed \textit{Separation Logic} as the solution to
this~\cite{separation-logic}. Separation Logic reasons about
\textit{heap fragments} (sometimes called \textit{heaplets}), which represent
sections of a theoretical computer's heap; it also provides three core features
in addition to the standard Hoare Logic:

\begin{figure}[!b]
  \centering
  \includegraphics[width=200px]{img/separating-conjunction.jpg}
  \caption{
    A visualisation of the separating conjunction.
    From~\cite{infer-sl}.
  }\label{fig:separating-conjunction}
\end{figure}

\begin{itemize}
  \item The \textit{heap cell assertion}, $\cell{x}{y}$, denotes that a heap
  fragment composes of a single cell at address $x$ with value $y$.

  \item The \textit{separating conjunction}, $P \lstar Q$, states that the heap
  fragment can be split into two disjoint (potentially empty) sub-fragments,
  one of which satisfies $P$, and the other satisfies~$Q$.

  \item The \textit{Frame Rule} --- a fundamental rule that allows derivations
  to temporarily ``forget'' any unneeded logic either not concerning
  heap-allocated memory, or concerning heap-allocated memory that isn't mutated
  by the command(s) currently being considered. Intuitively, this states that
  any programs that can execute on a state $P$ can also execute on a larger
  state, $P \lstar R$. The Frame Rule is as follows:

  \[
    \inferrule[Frame]{
      \triple{P}{C}{Q} \quad \mathtt{mod}(C) \cap \mathtt{fv}(R) =  %chktex 35
      \emptyset}{\triple{P \lstar R}{C}{Q \lstar R}
    }
  \]
\end{itemize}


Separation logic made its first foray into automatic analysis tools with the
creation of \textbf{Smallfoot}~\cite{smallfoot-paper, smallfoot-site}. It works
on a small while language with static objects, requiring pre- and
post-conditions and loop invariants, and has the ability to reason about simple
data structures such as lists and trees.

The utility of separation in tooling was expanded with the development of
bi-abudction techniques; bi-abduction is a method of symbolic program analysis
that can automatically infer the pre- and post-condition of functions.
\textbf{SpaceInvader} was introduced with the ability to infer some loop
invariants in small C code, with \textbf{Abductor} later added to introduce
bi-abduction to the toolset~\cite{abductor}.

2011 saw the introduction of \textbf{VeriFast}~\cite{verifast-paper,
  verifast-repo}, `a prototype verification tool for single-threaded and
multithreaded C and Java programs'. VeriFast performs verification similar to
Gillian, working on functions with developer-defined pre- and post-conditions,
also using an intermediate representation to do so.
\autoref{fig:verifast-example} and \autoref{fig:verifast-example-output} show
how VeriFast handles a small Java program that deliberately dereferences a null
pointer.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{java}
class VerifastTest {
    int nullDeref()
        //@ requires true;
        //@ ensures 0 <= result;
    {
        String str = null;
        return str.length();
    }
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{\texttt{VerifastTest.java}}~
\label{fig:verifast-example}
\vspace{0.5cm}

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
> verifast ./VerifastTest.java
./VerifastTest.java
./VerifastTest.java(7,20-26): Target of method call might be null.
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{Output from analysing \texttt{VerifastTest.java}}~
\label{fig:verifast-example-output}
\vspace{0.5cm}

In industry, probably the most prominent use of a tool built on separation logic
is Facebook's \textbf{Infer}~\cite{infer, infer-site}; it's a static analysis
tool for Java and C/C++/Objective-C, designed to use bi-abduction to provide
users with a list of potential bugs, crashes, and sources of poor performance.
Similarly to Gillian, Infer is written in OCaml, and works by compiling source
code to an intermediate representation. In contrast, Infer wholly focuses on
automated compositional testing, and refines this process to a state in which
it can easily be used in industry, whilst also including more general analysis
for concerns such as security and concurrency; it sacrifices depth of analysis
to result in a lightweight tool that gives developer-friendly feedback.
Infer doesn't require a full program in order to perform analysis, as it only
needs to construct Hoare triples for one function at a time. This, combined with
its ability to reuse existing results from unchanged functions and only consider
modified code, makes for a fast and hugely scalable static analysis tool, used
as part of Facebook's code quality pipeline for all modifications to the Android
and iOS apps for Facebook, Facebook Messenger, Instagram, and others
services~\cite{infer-about}. Infer outputs discovered errors and warnings to a
file in CSV, whilst directly outputting the most severe.
\autoref{fig:infer-example} and \autoref{fig:infer-example-output} show a short
example of running Infer on a similar function to what was tested with VeriFast.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{java}
class InferTest {
    // Deliberately call a method on a null pointer
    int nullDeref() {
        String str = null;
        return str.length();
    }
}
\end{minted}
\vspace{-0.6cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{\texttt{InferTest.java}}~
\label{fig:infer-example}
\vspace{0.5cm}

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
> infer -- javac ./InferTest.java
Starting analysis (Infer v0.5.0)

... (skipping some lines) ...

Found 1 issue
InferTest.java:5: error: NULL_DEREFERENCE
  object str last assigned on line 4 could be null and is
  dereferenced at line 5.
  3.       int nullDeref() {
  4.           String str = null;
  5. >         return str.length();
  6.       }
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{Output from analysing \texttt{InferTest.java}}~
\label{fig:infer-example-output}
\vspace{0.5cm}

Both VeriFast and Infer produce clear and direct feedback about the null
dereference error, providing line numbers (and even column numbers, in
VeriFast's case) and a clear cause of the error.

\subsection{Reaching beyond separation logic}

Currently, Infer is not limited to using separation-logic-based techniques for
bug finding, developing checks that make use of various other program analysis
in order to broaden the scope of errors that Infer can report, through the use
of \textbf{abstract interpretations} (AI); this entails the exploration of all
possible states of a program through a series of over-approximations (a deeper
understanding is outside the scope of this project).

A strong source of inspiration for Infer's AI techniques is
\textbf{Frama-C}~\cite{frama-c-paper, frama-c-site}, `a source code analysis
platform that aims at conducting verification of industrial-size C programs'; a
noteworthy feature of Frama-C is its debugger-esque graphical interfaces
available for certain analyses.


\subsection{Debugging}

Whilst the depth of analyses via separation logic has increased over the years,
clarity of error reporting remains difficult to maintain. Until recent work on
Gillian by Matthew Ho~\cite{gillian-debugging-2021}, VeriFast's clear-cut
advantage over similar tools was its functioning debugger, and succinct,
immediate error reporting; as found in previous
comparisons~\cite{gillian-logging-2020}, upon attempting to verify an invalid
program, VeriFast will directly output its reasoning for the error, and the line
number responsible. VeriFast remains ahead of Gillian's debugging capabilities
--- whilst the work of Ho from 2021 markedly closed the gap between the two
tools (and provided more specific and helpful error reporting, in Gillian, as
well as some ease-of-use features such as debugging specific functions),
the DAP's limitations on Gillian debugging left for some sorely missed features,
such as the VeriFast debugger's ability to jump to any symbolic execution step,
and visually show when resources allocated on the heap are freed. As of the
beginning of this project, the ability to select execution branch when debugging
is absent from both Gillian and VeriFast.
\autoref{fig:verifast-debugging-example} shows VeriFast's debugging interface.

\begin{figure}
  \centering
  \includegraphics[width=0.75\textwidth]{img/verifast-debugging-example.png}
  \caption{
    An example of VeriFast's debugging interface, using the program from
    \autoref{fig:verifast-example}
  }\label{fig:verifast-debugging-example}
\end{figure}

\section{Gillian}\label{sec:background:gillian}

Gillian is a platform for program analysis based on separation logic, whose
goal is to be extendable to as many programming languages as possible --- this
shines through in Gillian's core ideology, which is to remove the burden of
reasoning about analyses from the user, and have them focus only on their
chosen target language's memory mode, reducing both workload and required
understanding from the user. As stated in \autoref{sec:intro}, one of
Gillian's biggest selling points is its parametricity on the target language's
memory model.

Gillian is currently instantiated to three target languages: a simple While
language (WISL), as well as JavaScript and C. Gillian's three modes of program
analysis were outlined in \autoref{sec:intro}, but they each deserve an
explanation in more detail. Note that automatic compositional testing is not
explained in further detail as it is outside the scope of this project.

\subsection{WISL --- memory model and syntax}
WISL is a simple while language used for experimental and educational purposes. Its memory model consists of blocks, each of which is uniquely identified by a location, and contains two components: a list of memory cells, mapping numerical offsets to values stored on the heap, and a natural-number bound, specifying the memory block's size.  WISL can track negative resource, originating when allocating or deallocating. For allocation, the negative information originates from the fact that a freshly allocated block of a given size must not have offsets beyond that size; this is captured by the bound. For deallocation, the negative information is that only entire blocks can be deleted, and is captured by the fact that a memory block can either map to a list of cells or a dedicated freed symbol.

The WISL syntax comprises the following statements:
\begin{itemize}
  \item \texttt{x := e}, which assigns the value of the expression \texttt{x} to the variable \texttt{x} in the store;
  \item \texttt{x := new(n)}, which allocates a new block consisting of \texttt{n} cells, setting its bound to n;
  \item \texttt{delete(x)}, which deallocates the block of memory at location given by \texttt{x}, and only works if \texttt{x} points to the first cell of the block and the bounds are known;
  \item \texttt{x := [e]}, which assigns the value contained in the memory cell at location \texttt{e} to the variable \texttt{x} in the store;
  \item \texttt{[e1] := e2}, which stores the value corresponding to \texttt{e2} in the memory cell at location \texttt{e1};
  \item \texttt{skip}, which does nothing;
  \item \texttt{while (b) \{stmt\}}, which executes the statement \texttt{stmt} while \texttt{b} is true; and
  \item \texttt{if (b) \{stmt1\} else \{stmt2\}}, which executes the statement \texttt{stmt1} if \texttt{b} is true, and otherwise it executes \texttt{stmt2}.
\end{itemize}

\subsection{Whole-program symbolic testing}

This mode of analysis invites developers to write unit tests that involve the
inclusion of \textit{symbolic values}, i.e.\ values that represent a range of
concrete ones. During execution, a symbolic interpreter keeps track of the
constraints on symbolic values that must hold for the program to be in the
current~state.

The following C programs outline some nuances of working with symbolic values.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{c}
int main(void) {
  int x = symb_int();
  if (x < 0) {
    printf("OK");
  } else {
    ASSERT(false);
  }
  return 0;
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - basic example}}
\vspace{0.5cm}

When executing line \texttt{2}, the interpreter creates a symbolic integer $x$,
and assigns it to the program variable \texttt{x}. At the \texttt{if} statement
at line \texttt{3}, both branches are considered, constraining the symbolic
value as necessary; the constraint for the `true' branch is \texttt{$\x < 0$}
whereas for the `false' branch, it is \texttt{$\lnot (x < 0)$}. The former will
successfully execute, but the latter branch will fail due to the unsatisfiable
assertion; this indicates that the code fails when $x$ is non-negative.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{c}
int main(void) {
  int x = symb_int();
  if (x < 0 && x > 10) {
    ASSERT(false);
  } else {
    printf("OK");
  }
  return 0;
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - non-executed branches}}
\vspace{0.5cm}

If a branch constrains symbolic values to the point where no concrete values
exist in its range (e.g.\ in this program, with $x$ being less than 0
\textit{and} greater than 10), then that branch will not be executed --- this
makes intuitive sense as such a situation is impossible.

While assert statements can be used to pinpoint if the execution ended up in an
undesirable branch, as in the example above, they are more commonly used in
conjunction with assume statements to prove correctness properties of code.
Assume statements extend the path condition with a given constraint. Take, for
example, the following program:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{c}
int main(void) {
  int x = symb_int();
  int y = symb_int();
  ASSUME(x > 0 && y > 0);
  int z = x + y;
  ASSERT(z > 0);
  return 0;
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - assume and assert}}
\vspace{0.5cm}

This example shows how assert statements are most commonly used --- in tandem
with assume statements, to prove properties of the code to be correct; the
constraints on symbolic variables can be extended manually using these assume
statements. Here, the assertion that the sum of two positive numbers is also
positive is made, which passes symbolic execution.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{c}
int main(void) {
  int x = symb_int();
  ASSUME(x < 0 && x > 10);
  ASSERT(false);
  return 0;
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - termination when unsatisfiable}}
\vspace{0.5cm}

Somewhat counter-intuitively, if execution is halted by the symbolic value
constraints becoming unsatisfiable, the test passes; this captures a sense of
a program being vacuously correct --- code can't cause an error if it can never
be executed concretely.

When considering code with loops, Gillian will unroll said loops up to a given
bound; whilst this gives a reasonable assurance of correctness, it is not a full
guarantee of correct code. This is emblematic of path explosion --- a core
difficulty surrounding symbolic execution --- where the amount of possible
execution branches grows exponentially. This decision was made as the risk of
missed failure paths is small enough to make the performance gain worthwhile.

Of course, the more interesting (or useful) cases are where the test fails;
consider this example:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{c}
#include <gillian-c/gillian-c.h>
#include <stdbool.h>
#include <stdlib.h>

int main(void) {
  int x = symb_int();
  int y = symb_int();
  if (x < 0) {
    ASSERT(false);
  } else {
    if (y < 0) {
      ASSERT(false);
    } else {
      return 0;
    }
  }
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - assertion failure}}
\vspace{0.5cm}

This program can fail in the `true' branch of either if-statement; the only
succeeding path occurs when both $x$ and $y$ are negative. This is the output
given by Gillian:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
Assert failed with argument ({{ "int", 0. }} == {{"int", 1.}}).
Failing Model:
  [ (#x: {{"int", #lvar1}}), (#lvar1: -1.), (#y: {{"int", #lvar0}}) ]
Assert failed with argument ({{ "int", 0. }} == {{"int", 1.}}).
Failing Model:
  [ (#lvar0: 0.),
    (#lvar1: -1.),
    (#x: {{ "int", #lvar0 }}),
    (#y: {{ "int", #lvar1 }}) ]
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Symbolic execution - assertion failure (Gillian output)}}
\vspace{0.5cm}

The cause of verification failure is not particularly obvious. This output is
trying to convey that it has found two failing paths, and has given a variable
configuration that leads to each; the \texttt{Assert failed with argument}
statement is the specific reason that the path fails, in this case describing
how it expects \texttt{true} to be passed to an assert statement, but instead it
received \texttt{false}. With some observation, it can be understood that the
first failure case occurs when $x$ is assigned -1, and the second when $y$ is
assigned -1, each causing the respective if-statement to evaluate to true.

This form of error reporting is one of Gillian's weak points; while it is very
good at finding such errors, its attempts at communicating them to the
developer could use improvement; even a simple program case such as this was
not entirely obvious to understand, so attempting to apply this to a larger
program would be cumbersome at best.

\subsection{Full verification --- an example in debugging}

Gillian's full verification is based upon principles of separation logic. When
moving from simple program state to more complex ideas such as data structures,
it becomes helpful to define predicates as shorthand for certain conditions.
For example, consider the predicate \texttt{list(x, $\alpha$)}, expressing a
linked list whose address is stored in program variable \texttt{x}, containing
the same elements as the mathematical list $\alpha$. This predicate is described
recursively, as either the empty list $\epsilon$, or a binary cell containing
the head of the list and a pointer to the remainder of the list. The
\texttt{list} predicate is as follows:
\begin{align*}
  \llist{\pvar{x}, \alpha} =\; &(\alpha \doteq \epsilon \ast \pvar{x} \doteq \nil)~\lor\\
  & (\exists b, \beta \ldotp \alpha \doteq (b : \beta) \lstar \exists y \ldotp \twocell{\pvar{x}}{b}{y} \ast \llist{y, \beta})
\end{align*}

Note that the separating conjunction ($\lstar$) specifies that
$\twocell{\pvar{x}}{b}{y}$ is disjoint from $\llist{y, \beta}$, therefore the
list is acyclic.

An additional predicate can also prove useful when reasoning about lists; the
list segment, which is similar to the list predicate, but specifies the address
at which the list segment ends; the linked list may continue, but that is out
of the scope of the predicate:
\begin{align*}
  \lseg{\pvar{x}}{\pvar{y}}{\alpha} =\; &(\alpha \doteq \epsilon \ast \pvar{x} \doteq \pvar{y})~\lor\\
  &(\exists b, \beta \ldotp \alpha \doteq (b : \beta) \ast \exists z \ldotp \twocell{\pvar{x}}{b}{z} \lstar \lseg{z}{\pvar{y}}{\beta})
\end{align*}

To test Gillian's verification, consider this iterative list length function,
written in WISL:\@

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
{ list(x, #alpha) }
function llen_iter(x) {
  y := x;
  n := 0;
  while (not (y = null)) {
    y := [y+1];
    n := n+1;
  };
  return n
}
{ list(x, #alpha) * (ret == len(#alpha)) }
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Verification example - list length in WISL}}
\vspace{0.5cm}

This is the standard iterative method of counting a linked list. The pre- and
post-conditions state that, given a list at \texttt{x} with contents
\texttt{\#alpha}, the list remains unchanged at \texttt{x}, and the function
returns the length of \texttt{\#alpha}.

Note that the list / list segment predicates must be defined in order to be used:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
predicate list(+x, alpha) {
    (alpha == nil) * (x == null);
    (alpha == #b :: #beta) * (x -> #b, #y) * list(#y, #beta)
}

predicate lseg(+x, +y, alpha) {
  (alpha == nil) * (x == y);
  (alpha == #b :: #beta) * (x -> #b, #z) * lseg(#z, y, #beta)
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\caption{List predicates in WISL}
\label{lst:list-predicate}

The following lemma must also be defined, stating that if a list segment
terminates with $\nil$, then it is equivalent to a full list:
\begin{align*}
  \lseg{\pvar{x}}{\nil}{\alpha} \iff \llist{\pvar{x}, \alpha}
\end{align*}

Note that Gillian allows the user to prove specified lemmas using a series of
logical commands, making use of unfolding, folding, auxiliary assertions, and
application of lemmas.

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
lemma lseg_to_list {
  statement:
    forall x, alpha.
      lseg(x, null, alpha) |- list(x, alpha)

  proof:
    unfold lseg(x, null, alpha);
    if (x = null) {
      fold list(x, alpha)
    } else {
      assert {exists: #z, #beta} (x + 1 -> #z) * lseg(#z, null, #beta);
      apply lseg_to_list(#z, #beta);
      fold list(x, alpha)
    }
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{List lemma in WISL}}
\vspace{0.5cm}

\ldots and Gillian approves:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
Verifying lemma lseg_to_list... Success
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{List lemma in WISL - Gillian output}}
\vspace{0.5cm}

A lemma to describe appending to a list segment is also required:
\begin{align*}
    \lseg{\pvar{x}}{\pvar{y}}{\alpha} \lstar \twocell{\pvar{y}}{a}{\pvar{z}} \iff \lseg{\pvar{x}}{\pvar{z}}{(\alpha \dot [a])}
\end{align*}

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
lemma lseg_append {
  statement:
    forall x, y, alpha, a, z.
      lseg(x, y, alpha) * (y -> a, z) |- lseg(x, z, alpha @ [a])
}
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{List segment lemma in WISL}}
\vspace{0.5cm}

At last, the program is ready for verification. Upon first attempt, an error is
produced:
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
wisl.exe: internal error, uncaught exception:
          Failure("While loop without invariant in Verification mode!")
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Attempted verification - no loop invariant}}
\vspace{0.5cm}

When verifying, Gillian requires the user to provide a loop invariant in order
to provide a full guarantee, as opposed to settling for unrolling. The correct
invariant captures progress through the function by tracking the segment of the
list that's already been counted and the remaining portion of the list that has
yet to be counted:
\begin{align*}
    \exists \alpha_1, \alpha_2 \ldotp (\alpha \doteq (\alpha_1 \dot \alpha_2)) \lstar \lseg{\pvar{x}}{\pvar{y}}{\alpha_1} \lstar (\pvar{n} \doteq | \alpha_1 |) \lstar \llist{\pvar{y}, \alpha_2}
\end{align*}

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
  ...
  [[ invariant {exists: #alpha1, #alpha2} (#alpha == #alpha1 @ #alpha2) * 
     lseg(#x, y, #alpha1) * (n == len #alpha1) * list(y, #alpha2)         ]];
  while (not (y = null)) {
    ...
  }
  ...
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{WISL list length - loop invariant}}
\vspace{0.5cm}

Upon attempting verification again, Gillian presents this:
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
wisl.exe: internal error, uncaught exception:
          Failure("WARNING: Failed to unify against the precondition of
          procedure llen_iter_loop0\nSTATE:\n  SPEC VARS: #alpha, #alpha1,
          #alpha2, #x\n  HEAP:\n    {\n(_\$l_6, (1 i+ _lvar_31))
          ->_lvar_33\n(_\$l_6, _lvar_31) -> _lvar_32\n}\n  STORE:\n    
          (gvar0: {{ ALoc _\$l_6, (BinOp: (1 i+ _lvar_31)) }})\n    (gvar1:
          {{ ALoc _\$l_6, (BinOp: (1 i+ _lvar_31)), LVar _lvar_33 }})\n    
          (gvar2: (BinOp: (1 i+ (l-len #alpha1))))\n    (n: (BinOp: (1 i+
          (l-len #alpha1))))\n    (y: LVar _lvar_33)\n  \n  
          PURE FORMULAE:\n    (_lvar_y == {{_\$l_6, _lvar_31}})\n    
          (#alpha == l+ (#alpha1, {{_lvar_32}}, _lvar_29))\n    (#alpha2 
          == l+ ({{_lvar_32}}, _lvar_29))\n  (_lvar_30 == _\$l_6)\n  
          \n  TYPING ENVIRONMENT:\n    (_lvar_29: List)\n    (_lvar_y:
          List)\n    (#alpha: List)\n    (#alpha2: List)\n    (#alpha1:
          List)\n    (_lvar_30: Obj)\n    (_lvar_31: Int)\n  PREDICATES:\n    
          list(_lvar_33, _lvar_29)\n    lseg(#x, {{_\$l_6, _lvar_31}}, 
          #alpha1)\n  ")
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Verification: WISL list length error - precondition not met}}
\vspace{0.5cm}

The error message provided is vague, referencing some imaginary function
\texttt{llen\_iter\_loop0}, followed by a slew of logical variable information
unfit for human understanding. The key to deciphering this is the knowledge that
Gillian internally compiles while loops to functions, and this unification
failure indicates that the loop invariant could not be re-established. To
understand why, the text file log must be investigated, at the last executed
command:
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
------------------------------------------------------
--llen_iter_loop0: 6--
TIME: 0.532037
CMD: loopretvar__ := "llen_iter_loop0"(n, y) 
       use_subst [invariant_spec - #alpha: #alpha, #x: #x]
BRANCHING: 1

SPEC VARS: #alpha, #alpha1, #alpha2, #x
HEAP:
  {
(_$l_6, (1 i+ _lvar_31)) -> _lvar_33
(_$l_6, _lvar_31) -> _lvar_32
}
STORE:
  (gvar0: {{ ALoc _\$l_6, (BinOp: (1 i+ _lvar_31)) }})
  (gvar1: {{ ALoc _\$l_6, (BinOp: (1 i+ _lvar_31)), LVar _lvar_33 }})
  (gvar2: (BinOp: (1 i+ (l-len #alpha1))))
  (n: (BinOp: (1 i+ (l-len #alpha1))))
  (y: LVar _lvar_33)

PURE FORMULAE:
  (_lvar_y == {{_\$l_6, _lvar_31}})
  (#alpha == l+ (#alpha1, {{_lvar_32}}, _lvar_29))
  (#alpha2 == l+ ({{_lvar_32}}, _lvar_29))
  (_lvar_30 == _\$l_6)

TYPING ENVIRONMENT:
  (_lvar_29: List)
  (_lvar_y: List)
  (#alpha: List)
  (#alpha2: List)
  (#alpha1: List)
  (_lvar_30: Obj)
  (_lvar_31: Int)
PREDICATES:
  list(_lvar_33, _lvar_29)
  lseg(#x, {{_\$l_6, _lvar_31}}, #alpha1)

------------------------------------------------------
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Loop invariant failure - Gillian log file}}
\vspace{0.5cm}


This shows that the last executed command was at the end of the loop's internal
function, calling itself to move to the next iteration; this further confirms
that the problem was with re-establishing the loop invariant.
\texttt{lseg(\#x, \{\{\_\$l\_6, \_lvar\_32\}\}, \#alpha1)} indicates that
Gillian is aware of a list containing $\alpha_1$, but inspecting the loop
invariant shows no sign of a list segment containing $(\alpha_1 \dot [b])$. This
is where the lemma \texttt{lseg\_append} comes into play, once inserted into
the loop:
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
  ...
  while (not (y = null)) {
    [[ assert {exists: #y, #b, #t} (y == #y) * (#y -> #b, #t) ]];
    y := [y+1];
    n := n+1;
    [[ apply lseg_append(#x, #y, #alpha1, #b, #t) ]]
  }
  ...
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Applying \texttt{lseg\_append}}}
\vspace{0.5cm}

Notice the inclusion of an assertion; this is used to establish names for the
logical variables to be use in the lemma application. With that in place,
verification can be attempted again:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
Obtaining specs to verify...
Obtaining lemmas to verify...
Obtained 4 symbolic tests in total
Running symbolic tests: 0.083106
Verifying lemma lseg_to_list... Success
Verifying lemma lseg_append... Success
Verifying one spec of procedure llen_iter... Failure
Verifying one spec of procedure llen_iter_loop0... Success
There were failures: 0.874831
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{WISL list length - list / list segment error}}
\vspace{0.5cm}

Failure once more. Referring to the logs once again reveals a problem at the
final hurdle, when returning from \texttt{llen\_iter()}:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
------------------------------------------------------
...
CMD: return
...
PREDICATES:
  lseg(#x, null, #alpha1)

------------------------------------------------------
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{WISL list length - list / list segment error, Gillian log file}}
\vspace{0.5cm}

Gillian knows about a list segment, but the post-condition requires a list;
perfect timing for the \texttt{lseg\_to\_list} lemma:

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
  ...
  [[ apply lseg_to_list(x, #alpha) ]];
  return n;
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Applying \texttt{lseg\_to\_list}}}
\vspace{0.5cm}

Verification is attempted a final time. Success at last!

\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\begin{minted}{text}
Obtaining specs to verify...
Obtaining lemmas to verify...
Obtained 4 symbolic tests in total
Running symbolic tests: 0.082395
Verifying lemma lseg_to_list... Success
Verifying lemma lseg_append... Success
Verifying one spec of procedure llen_iter... Success
Verifying one spec of procedure llen_iter_loop0... Success
All specs succeeded: 0.601923
\end{minted}
\vspace{-0.4cm}
\noindent\rule{\textwidth}{0.5pt}
\vspace{-0.6cm}
\captionof{listing}{{Verification: WISL list length success}}
\vspace{0.5cm}

Working through this process shows that, while Gillian is very capable at its
purpose of proving correctness of programs, the roundabout debugging process is
unreasonably awkward for real-world use. Even for a small example such as this,
the user not only requires a strong understanding of separation logic, but also
knowledge of Gillian's underlying semantics, and how it converts target
languages to GIL.\@

\section{Engineering resources and tools}\label{sec:background:engineering-tools}

The nature of the project required research into the language and tools that
are/could be/will be used in the current/further development of Gillian.

\subsection{Building OCaml projects}

Created in 1996, \textit{OCaml}~\cite{ocaml} is `an industrial-strength
programming language supporting functional, imperative and object-oriented
styles'. Specifically, OCaml provides the ability to make use of functional,
imperative, and object-oriented styles. This, combined with its powerful type
system, makes it a good fit for symbolic analysis tools. Many of Gillian's
contemporaries, including Infer, VeriFast and Frama-C, are also written in
OCaml.

OCaml's most popular build system is \textit{Dune}~\cite{dune} --- it allows the
easy compilation of multi-file OCaml programs and libraries, including
dependencies from \textit{OPAM}~\cite{opam}, OCaml's designated public library
repository. Despite Dune's popularity, it is a fairly bare-bones system, quickly
growing cumbersome when developing larger projects and, in particular,
switching development between projects; Dune requires that OPAM dependencies
are installed system-wide, which can lead to inconsistent builds and version
conflicts. The answer to these concerns is \textit{esy}~\cite{esy}, a package
management system for OCaml and Reason styled after \textit{npm}~\cite{npm}.
Esy provides `provides a fast and powerful workflow for local development of
OPAM packages without requiring ``switches''\,', meaning dependencies are
isolated between projects. Esy also provides a number of convenience features,
such as defining custom commands that run within the OCaml project's
environment, as well as supporting non- OPAM dependencies, e.g. OCaml sources
from GitHub repositories (optionally at a specific commit).

Knowledge of these build systems will become paramount when introducing the
somewhat foreign element that is a VSCode extension.

\subsection{VSCode and its extensions}\label{sec:vscode}

VSCode (Visual Studio Code)~\cite{vscode} is a universally recognised text
editor and development environment, developed by Microsoft. It currently stands
as the most popular development worldwide, enjoying a 71\% market share
according to Stack Overflow's 2021 developer survey
~\cite{stack-overflow-survey-editors}.

A large factor to VSCode's success is its extensive support for extensions,
boasting over 24,000 freely-distributed extensions~\cite{vscode-features},
ranging from language-specific support to general developer creature comforts
(such as SSH support). Developing new extensions is made very accessible through
simple JavaScript or TypeScript projects~\cite{vscode-extensions-intro}, making
use of VSCode's well-documented API~\cite{vscode-api} to have a large degree of
control over the editor.

Whilst VSCode limits the extent to which extensions can extend the editor's UI,
extension authors are able to make use of webviews~\cite{vscode-webview}; an
extension can open an editor tab that contains web content (HTML/CSS/JS) that
the extension has complete control over, providing a method for extensions to
fill in any gaps in VSCode's UI.\@

\begin{figure}
  \center{}
  \includegraphics[width=400px]{img/webview-example.png}
  \caption{An example of a webview created by a VSCode extension}%
  \label{fig:webview-example}
\end{figure}


\myparagraph{Debug Adapter Protocol.}
A common issue when adding IDE support for development tools is the sheer
number of editors that would ideally be supported~\cite{magpiebridge}. Whilst
VSCode has a huge market share, only supporting VSCode would neglect a
significant portion of developers. Unfortunately, maintaining support for many
editors at once is an unreasonably large undertaking. The \textit{Debug Adapter
Protocol} (DAP)~\cite{dap} exists as an attempted countermeasure to this issue,
turning the $O(m \times n)$ complexity problem of supporting many debuggers on
many editors into an $O(m + n)$ problem; each debugger and each editor need only
be integrated once.

\begin{figure}[!t]
  \centering
  \includegraphics[width=0.5\textwidth]{img/dap-diagram.png}
  \caption{
    DAP:\@ an interface between arbitrary IDEs and
    arbitrary debuggers~\cite{dap}.
  }\label{fig:dap-diagram}
\end{figure}

As discussed in \autoref{sec:intro}, the DAP's limited set of
included commands proved a limiting factor in the development of a Gillian
debugger. A potential solution is to make use of custom commands and events,
which is supported both by
VSCode~\cite{vscode-dap-custom-request, vscode-dap-custom-event} and the OCaml
DAP implementation currently used in Gillan's debugger~\cite{ocaml-dap} (where
custom events and commands are defined similarly to those already
provided~\cite{ocaml-dap-custom}).


\myparagraph{Inclusion of OCaml code.}
Resulting of Ocsigen's work as part of their OCaml web framework
~\cite{ocsigen-framework}, OCaml programs can be directly compiled into
JavaScript using their \texttt{Js\_of\_ocaml} package~\cite{js-of-ocaml}; by
adding a compilation flag in a project's Dune file, the relevant program can be
compiled to a \texttt{.js} file instead of a native binary. This produced file
doesn't need to be used as its own program; using the provided JS
bindings~\cite{js-of-ocaml-bindings}, the resulting JS code can export
functions and values, just like normal JS code, to be used elsewhere in a
JavaScript project.

Another option is to make use of the OCaml VSCode bindings
~\cite{vscode-ocaml-bindings} provided by OCamlLabs'
\texttt{vscode-ocaml-platform}~\cite{vscode-ocaml-platform, ocamllabs}; this
way, no JavaScript need be written at all.

These options allow the line between JavaScript and OCaml to be drawn wherever
is most opportune; the extension could be written completely in JavaScript,
requiring more attention when interacting with Gillian's debugger; the
extension could be entirely OCaml, sacrificing more succinct integration with
VSCode for a more unified codebase with Gillian; it is just as possible to draw
the line somewhere in-between, exposing the more Gillian-related OCaml code via
functions to the JavaScript that communicates with VSCode. Additionally, both
scenarios allow for Gillian code to be shared with the extension. However,
with the Gillian libraries as they are, such libraries cannot be haphazardly
included in the extension code; \texttt{Js\_of\_ocaml} transitively includes all
OCaml dependencies, potentially leading to code that cannot be executed. As a
concrete example to this, attempting to include Gillian's \texttt{debugAdapter}
library results in errors, due to the compiler's attempt to include an SQLite
implementation, which it simply is not equipped to handle. Aside from this, the
inclusion of unnecessary dependencies in JS-compiled code results in a hugely
bloated extension --- the \texttt{debugAdapter} example created a compiled JS
file over a million lines long. The ideal scenario here is to move shared
Gillian code to its own library within Gillian, which has as few dependencies as
possible (ideally none), but on which both Gillian and the extension code would
then depend.

\begin{sidewaysfigure}
  \center{}
  \includegraphics[width=0.8\textwidth]{img/vscode-extension-with-ocaml.png}
  \caption{The process of including OCaml code in a VSCode extension}%
  \label{fig:vscode-extension-with-ocaml}
\end{sidewaysfigure}

\myparagraph{Putting it all together.}\label{sec:background:extending-dap}
A combination of DAP custom events and VSCode's webviews could allow us to move
past DAP's initial limitations. This, however, comes at the cost of creating an
implementation specific to VSCode, eliminating a large benefit of using the DAP
in the first place.

A working example that tests custom DAP commands/events, webviews and the
inclusion of OCaml code (alongside a Gillian library) is available
at~\cite{debugger-experiment}.

\subsection{MagpieBridge}\label{sec:background:magpiebridge}

Similarly to program debugging, adding support for static code analysers to IDEs
is limited by the amount of tools and IDEs that support must be added for. In a
similar notion to the DAP, MagpieBridge~\cite{magpiebridge} is `a framework for
integrating Static Analyses into IDEs and Editors with the Language Server
Protocol'~\cite{magpiebridge-repo}. The \textit{Language Server Protocol}
(LSP)~\cite{lsp} is another of Microsoft's creations, similar to the DAP, which
adds an arbitrary interface bridging IDEs and language tools (syntax checkers,
intellisense, etc.). As an example, MagpieBridge has a provided fully
functional integration for~Infer~\cite{infer-ide}.

A particular feature of MagpieBridge is its ability to serve a configuration
webpage, in which the user can configure the static analysis in their browser
of choice. Unfortunately, this pre-generated page can't contain any custom
content, and can only be used for configuration --- this would prohibit advanced
debugging features from being served directly from a MagpieBridge server.

Additionally, the inclusion of MagpieBridge would involve the addition of Java
to the language base of Gillian, increasing complexity of the project and
potentially harming long-term usability.


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{img/magpiebridge-goal.png}
  \caption{
    The goal of MagpieBridge; bridging static analysis tools with IDEs.
    From~\cite{magpiebridge-repo}.
  }\label{fig:magpiebridge-goal}
\end{figure}
